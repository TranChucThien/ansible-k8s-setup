# Playbook to join additional master nodes to existing Kubernetes cluster
# ⚠️  WARNING: This is for TESTING/LAB purposes only - NOT production best practice
# Production requires proper Load Balancer and HA setup
# 
# PREREQUISITE: Run 02-master.yaml first to initialize the first master
# This playbook joins masters[1:] (2nd, 3rd masters) to the cluster

---
- name: Join additional master nodes to cluster
  hosts: masters[1:]  # Skip first master (already initialized)
  become: yes
  tasks:

    # Step 0: Check if controlPlaneEndpoint is configured
    - name: Check kubeadm-config for controlPlaneEndpoint
      shell: kubectl get configmap kubeadm-config -n kube-system -o yaml | grep controlPlaneEndpoint
      environment:
        KUBECONFIG: "/etc/kubernetes/admin.conf"
      register: endpoint_check
      delegate_to: "{{ groups['masters'][0] }}"
      run_once: true
      failed_when: false

    - name: Debug endpoint check result
      debug:
        msg: |
          Endpoint check stdout: {{ endpoint_check.stdout }}
          Endpoint check stderr: {{ endpoint_check.stderr }}
          Endpoint check rc: {{ endpoint_check.rc }}
          Contains controlPlaneEndpoint: {{ 'controlPlaneEndpoint' in endpoint_check.stdout }}
      run_once: true

    - name: Create patch file for kubeadm-config
      copy:
        dest: /tmp/kubeadm-config-patch.yaml
        content: |
          data:
            ClusterConfiguration: |
              apiServer:
                timeoutForControlPlane: 4m0s
              apiVersion: kubeadm.k8s.io/v1beta3
              certificatesDir: /etc/kubernetes/pki
              clusterName: kubernetes
              controlPlaneEndpoint: "{{ groups['masters'][0] }}:6443"
              controllerManager: {}
              dns: {}
              etcd:
                local:
                  dataDir: /var/lib/etcd
              imageRepository: registry.k8s.io
              kind: ClusterConfiguration
              kubernetesVersion: v1.33.0
              networking:
                dnsDomain: cluster.local
                podSubnet: 10.10.0.0/16
                serviceSubnet: 10.96.0.0/12
              scheduler: {}
      delegate_to: "{{ groups['masters'][0] }}"
      run_once: true
      when: "'controlPlaneEndpoint' not in endpoint_check.stdout"

    - name: Patch kubeadm-config to add controlPlaneEndpoint if missing
      shell: kubectl patch configmap kubeadm-config -n kube-system --patch-file /tmp/kubeadm-config-patch.yaml
      environment:
        KUBECONFIG: "/etc/kubernetes/admin.conf"
      delegate_to: "{{ groups['masters'][0] }}"
      run_once: true
      when: "'controlPlaneEndpoint' not in endpoint_check.stdout"

    - name: Verify controlPlaneEndpoint is now configured
      shell: kubectl get configmap kubeadm-config -n kube-system -o yaml | grep controlPlaneEndpoint
      environment:
        KUBECONFIG: "/etc/kubernetes/admin.conf"
      register: endpoint_verify
      delegate_to: "{{ groups['masters'][0] }}"
      run_once: true
      when: "'controlPlaneEndpoint' not in endpoint_check.stdout"

    - name: Show patched controlPlaneEndpoint
      debug:
        msg: "controlPlaneEndpoint has been added: {{ endpoint_verify.stdout }}"
      run_once: true
      when: "'controlPlaneEndpoint' not in endpoint_check.stdout and endpoint_verify is defined"

    # Step 1: Get certificate key from first master (TTL: 2 hours)
    - name: Generate certificate key on first master
      command: kubeadm init phase upload-certs --upload-certs
      environment:
        KUBECONFIG: "/etc/kubernetes/admin.conf"
      register: cert_key_output
      delegate_to: "{{ groups['masters'][0] }}"
      run_once: true

    # Step 2: Extract certificate key
    - name: Extract certificate key
      set_fact:
        certificate_key: "{{ cert_key_output.stdout_lines[-1] }}"
      run_once: true

    # Step 3: Get join command for control plane
    - name: Get control plane join command
      shell: |
        kubeadm token create --print-join-command --certificate-key {{ certificate_key }}
      environment:
        KUBECONFIG: "/etc/kubernetes/admin.conf"
      register: control_plane_join_cmd
      delegate_to: "{{ groups['masters'][0] }}"
      run_once: true

    # Step 4: Join as control plane node
    - name: Join node as control plane
      command: "{{ control_plane_join_cmd.stdout }}"
      args:
        creates: /etc/kubernetes/admin.conf

    # Step 5: Setup kubectl for new master
    - name: Create .kube directory
      file:
        path: "/home/{{ ansible_user }}/.kube"
        state: directory
        owner: "{{ ansible_user }}"
        group: "{{ ansible_user }}"
        mode: '0755'

    - name: Copy admin.conf to user kube config
      copy:
        src: /etc/kubernetes/admin.conf
        dest: "/home/{{ ansible_user }}/.kube/config"
        remote_src: yes
        owner: "{{ ansible_user }}"
        group: "{{ ansible_user }}"
        mode: '0644'

    # Step 6: Verify new master joined successfully
    - name: Verify cluster status
      command: kubectl get nodes
      environment:
        KUBECONFIG: "/home/{{ ansible_user }}/.kube/config"
      register: cluster_status

    - name: Show cluster status
      debug:
        var: cluster_status.stdout_lines

    # Step 7: Verify etcd cluster
    - name: Check etcd members
      command: kubectl get pods -n kube-system -l component=etcd
      environment:
        KUBECONFIG: "/home/{{ ansible_user }}/.kube/config"
      register: etcd_status

    - name: Show etcd status
      debug:
        var: etcd_status.stdout_lines