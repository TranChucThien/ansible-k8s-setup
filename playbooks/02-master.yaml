# This playbook sets up a Kubernetes master node with Calico networking
# It performs the following steps:
# 1. Initializes the Kubernetes cluster with a specific pod network CIDR
# 2. Configures kubectl access for the ansible user
# 3. Extracts the join command for worker nodes
# 4. Installs and configures the Calico CNI plugin

---
- name: Setup Kubernetes master with Calico network
  hosts: masters
  become: yes
  tasks:

    # Step 1: Initialize the Kubernetes cluster with kubeadm
    # Uses 10.10.0.0/16 as the pod network CIDR
    # Only runs if admin.conf doesn't exist (idempotency)
    - name: Step 1 - Initialize Kubernetes cluster
      command: kubeadm init --pod-network-cidr=10.10.0.0/16
      register: kubeadm_init_output
      args:
        creates: /etc/kubernetes/admin.conf

    # Step 2: Display the output from kubeadm init for debugging
    - name: Step 2 - Show kubeadm init output
      debug:
        var: kubeadm_init_output.stdout

    # Step 3: Create .kube directory for the ansible user to store kubectl config
    - name: Step 3 - Create .kube directory for user
      file:
        path: "/home/{{ ansible_user }}/.kube"
        state: directory
        owner: "{{ ansible_user }}"
        group: "{{ ansible_user }}"
        mode: '0755'

    # Step 4: Copy the kubectl admin config to user's home directory
    - name: Step 4 - Copy admin.conf to user kube config
      copy:
        src: /etc/kubernetes/admin.conf
        dest: "/home/{{ ansible_user }}/.kube/config"
        remote_src: yes
        owner: "{{ ansible_user }}"
        group: "{{ ansible_user }}"
        mode: '0644'

    # Step 5: Generate the kubeadm join command for worker nodes
    - name: Step 5 - Extract join command for workers
      shell: kubeadm token create --print-join-command
      register: join_cmd

    # Step 6: Save the join command to a local file for later use
    - name: Step 6 - Save join command locally
      local_action: copy content="{{ join_cmd.stdout }}" dest="./join-command.txt"
      run_once: true
      become: no

    #######################################################
    # Calico Network Plugin Installation
    #######################################################

    # Step 7: Install the Calico operator using kubectl
    - name: Step 7 - Deploy Calico operator
      command: kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.28.0/manifests/tigera-operator.yaml
      environment:
        KUBECONFIG: "/home/{{ ansible_user }}/.kube/config"
      ignore_errors: yes

    # Step 8: Download the Calico custom resources manifest
    - name: Step 8 - Download Calico custom-resources file
      get_url:
        url: https://raw.githubusercontent.com/projectcalico/calico/v3.28.0/manifests/custom-resources.yaml
        dest: /tmp/custom-resources.yaml

    # Step 9: Update the CIDR in custom resources to match cluster pod CIDR
    - name: Step 9 - Update CIDR in custom-resources.yaml
      replace:
        path: /tmp/custom-resources.yaml
        regexp: 'cidr: 192\.168\.0\.0/16'
        replace: 'cidr: 10.10.0.0/16'

    # Step 10: Apply the modified Calico custom resources
    - name: Step 10 - Apply Calico custom resources
      command: kubectl apply -f /tmp/custom-resources.yaml
      environment:
        KUBECONFIG: "/home/{{ ansible_user }}/.kube/config"
      ignore_errors: yes

    # Step 11: Verify cluster node status
    # Retries up to 5 times with 10 second delay
    # Ensures at least the master node is in Ready state
    - name: Step 11 - Wait for all nodes to be ready (at least master)
      command: kubectl get nodes
      register: nodes_status
      environment:
        KUBECONFIG: "/home/{{ ansible_user }}/.kube/config"
      retries: 5
      delay: 10
      until: "'Ready' in nodes_status.stdout"
      check_mode: no

# ---
# - name: Setup Kubernetes master with Calico network
#   hosts: masters
#   become: yes
#   tasks:

#     - name: Initialize Kubernetes cluster
#       command: kubeadm init --pod-network-cidr=10.10.0.0/16
#       register: kubeadm_init_output
#       args:
#         creates: /etc/kubernetes/admin.conf

#     - name: Show kubeadm init output
#       debug:
#         var: kubeadm_init_output.stdout

#     - name: Create .kube directory for user
#       file:
#         path: "/home/{{ ansible_user }}/.kube"
#         state: directory
#         owner: "{{ ansible_user }}"
#         group: "{{ ansible_user }}"
#         mode: '0755'

#     - name: Copy admin.conf to user kube config
#       copy:
#         src: /etc/kubernetes/admin.conf
#         dest: "/home/{{ ansible_user }}/.kube/config"
#         remote_src: yes
#         owner: "{{ ansible_user }}"
#         group: "{{ ansible_user }}"
#         mode: '0644'

#     - name: Extract join command for workers
#       shell: kubeadm token create --print-join-command
#       register: join_cmd

#     - name: Save join command locally
#       local_action: copy content="{{ join_cmd.stdout }}" dest="./join-command.txt"
#       run_once: true
#       become: no

#     #######################################################
#     # Step 8: Install Calico network plugin
#     #######################################################

#     - name: Deploy Calico operator
#       command: kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.28.0/manifests/tigera-operator.yaml
#       environment:
#         KUBECONFIG: "/home/{{ ansible_user }}/.kube/config"
#       ignore_errors: yes

#     - name: Download Calico custom-resources file
#       get_url:
#         url: https://raw.githubusercontent.com/projectcalico/calico/v3.28.0/manifests/custom-resources.yaml
#         dest: /tmp/custom-resources.yaml

#     - name: Update CIDR in custom-resources.yaml
#       replace:
#         path: /tmp/custom-resources.yaml
#         regexp: 'cidr: 192\.168\.0\.0/16'
#         replace: 'cidr: 10.10.0.0/16'

#     - name: Apply Calico custom resources
#       command: kubectl apply -f /tmp/custom-resources.yaml
#       environment:
#         KUBECONFIG: "/home/{{ ansible_user }}/.kube/config"
#       ignore_errors: yes

#     - name: Wait for all nodes to be ready (at least master)
#       command: kubectl get nodes
#       register: nodes_status
#       environment:
#         KUBECONFIG: "/home/{{ ansible_user }}/.kube/config"
#       retries: 5
#       delay: 10
#       until: "'Ready' in nodes_status.stdout"
